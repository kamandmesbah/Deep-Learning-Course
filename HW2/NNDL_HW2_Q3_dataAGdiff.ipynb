{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtb4cU5S5iCB",
        "outputId": "60484e47-72d1-4be9-dad8-8f2b642a7270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/NNDL/HW2/Q3/Dataset.zip'"
      ],
      "metadata": {
        "id": "KNrmspPp726H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/Dataset/xray_dataset_covid19/augmentation_1\"\n",
        "\n",
        "!rm -rf \"/content/Dataset/xray_dataset_covid19/augmentation_2\""
      ],
      "metadata": {
        "id": "KsTLt9q39UuZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "\n",
        "\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
        "from PIL import Image\n",
        "\n",
        "def rotate_images(folder_path, save_folder, angle):\n",
        "    # Create the save folder if it doesn't exist\n",
        "    if save_folder and not os.path.exists(save_folder):\n",
        "        os.makedirs(save_folder)\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "            # Load the image\n",
        "            image = load_img(file_path)\n",
        "            image = img_to_array(image)\n",
        "\n",
        "            # Rotate the image\n",
        "            rotated_image = Image.fromarray(image.astype('uint8'), 'RGB').rotate(angle, expand=True)\n",
        "\n",
        "            # Save the rotated image\n",
        "            if save_folder:\n",
        "                save_path = os.path.join(save_folder, str(angle)+filename)\n",
        "            else:\n",
        "                save_path = file_path  # Overwrite the original image\n",
        "\n",
        "            rotated_image.save(save_path)\n",
        "\n",
        "\n",
        "\n",
        "def flip_images(folder_path, save_folder, flip_horizontal=True, flip_vertical=False):\n",
        "    # Create the save folder if it doesn't exist\n",
        "    if save_folder and not os.path.exists(save_folder):\n",
        "        os.makedirs(save_folder)\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "            # Load the image\n",
        "            image = load_img(file_path)\n",
        "            image = img_to_array(image)\n",
        "            image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\n",
        "            # Flip the image if specified\n",
        "            if flip_horizontal:\n",
        "                image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            if flip_vertical:\n",
        "                image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "\n",
        "            # Save the flipped image\n",
        "            if save_folder:\n",
        "                save_path = os.path.join(save_folder, 'fillped'+filename)\n",
        "            else:\n",
        "                save_path = file_path  # Overwrite the original image\n",
        "\n",
        "            image.save(save_path)\n",
        "\n",
        "angles_1  = [0,90]\n",
        "for angle in angles_1 :\n",
        "    folder_path = '/content/Dataset/xray_dataset_covid19/train/COVID'\n",
        "    save_folder = '/content/Dataset/xray_dataset_covid19/augmentation_1/train/COVID'\n",
        "    rotate_images(folder_path, save_folder , angle)\n",
        "\n",
        "    folder_path = '/content/Dataset/xray_dataset_covid19/train/NORMAL'\n",
        "    save_folder = '/content/Dataset/xray_dataset_covid19/augmentation_1/train/NORMAL'\n",
        "    rotate_images(folder_path, save_folder , angle)\n",
        "\n",
        "angles_2  = [0,90,180]\n",
        "for angle in angles_2 :\n",
        "    folder_path = '/content/Dataset/xray_dataset_covid19/train/COVID'\n",
        "    save_folder = '/content/Dataset/xray_dataset_covid19/augmentation_2/train/COVID'\n",
        "    rotate_images(folder_path, save_folder , angle)\n",
        "\n",
        "    folder_path = '/content/Dataset/xray_dataset_covid19/train/NORMAL'\n",
        "    save_folder = '/content/Dataset/xray_dataset_covid19/augmentation_2/train/NORMAL'\n",
        "    rotate_images(folder_path, save_folder , angle)"
      ],
      "metadata": {
        "id": "6khsvXpC554o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "angles_3  = [0,90,180,270]\n",
        "for angle in angles_3 :\n",
        "    folder_path = '/content/Dataset/xray_dataset_covid19/train/COVID'\n",
        "    save_folder = '/content/Dataset/xray_dataset_covid19/augmentation_3/train/COVID'\n",
        "    rotate_images(folder_path, save_folder , angle)\n",
        "\n",
        "    folder_path = '/content/Dataset/xray_dataset_covid19/train/NORMAL'\n",
        "    save_folder = '/content/Dataset/xray_dataset_covid19/augmentation_3/train/NORMAL'\n",
        "    rotate_images(folder_path, save_folder , angle)"
      ],
      "metadata": {
        "id": "HmqRrSichWhh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "\n",
        "train_ds_1 = tensorflow.keras.utils.image_dataset_from_directory(\n",
        "    directory ='/content/Dataset/xray_dataset_covid19/augmentation_1/train',\n",
        "    image_size = (150, 150),\n",
        "    validation_split = 0.15,\n",
        "    subset = \"training\",\n",
        "    seed = 42,\n",
        "    shuffle = True\n",
        "    )\n",
        "\n",
        "val_ds_1 = tensorflow.keras.utils.image_dataset_from_directory(\n",
        "    directory ='/content/Dataset/xray_dataset_covid19/augmentation_1/train',\n",
        "    image_size = (150, 150),\n",
        "    validation_split = 0.15,\n",
        "    subset = \"validation\",\n",
        "    seed = 42,\n",
        "    shuffle = True\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "train_ds_2 = tensorflow.keras.utils.image_dataset_from_directory(\n",
        "    directory ='/content/Dataset/xray_dataset_covid19/augmentation_2/train',\n",
        "    image_size = (150, 150),\n",
        "    validation_split = 0.15,\n",
        "    subset = \"training\",\n",
        "    seed = 42,\n",
        "    shuffle = True\n",
        "    )\n",
        "\n",
        "val_ds_2 = tensorflow.keras.utils.image_dataset_from_directory(\n",
        "    directory ='/content/Dataset/xray_dataset_covid19/augmentation_2/train',\n",
        "    image_size = (150, 150),\n",
        "    validation_split = 0.15,\n",
        "    subset = \"validation\",\n",
        "    seed = 42,\n",
        "    shuffle = True\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cksyf8O86mFv",
        "outputId": "8fa9bf17-9a40-41da-858e-43b4a229f968"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 296 files belonging to 2 classes.\n",
            "Using 252 files for training.\n",
            "Found 296 files belonging to 2 classes.\n",
            "Using 44 files for validation.\n",
            "Found 444 files belonging to 2 classes.\n",
            "Using 378 files for training.\n",
            "Found 444 files belonging to 2 classes.\n",
            "Using 66 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_ds_3 = tensorflow.keras.utils.image_dataset_from_directory(\n",
        "    directory ='/content/Dataset/xray_dataset_covid19/augmentation_3/train',\n",
        "    image_size = (150, 150),\n",
        "    validation_split = 0.15,\n",
        "    subset = \"training\",\n",
        "    seed = 42,\n",
        "    shuffle = True\n",
        "    )\n",
        "\n",
        "val_ds_3 = tensorflow.keras.utils.image_dataset_from_directory(\n",
        "    directory ='/content/Dataset/xray_dataset_covid19/augmentation_3/train',\n",
        "    image_size = (150, 150),\n",
        "    validation_split = 0.15,\n",
        "    subset = \"validation\",\n",
        "    seed = 42,\n",
        "    shuffle = True\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqyWVpFwhfa_",
        "outputId": "71276c3d-510b-45a1-efd1-4093c591fc62"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 592 files belonging to 2 classes.\n",
            "Using 504 files for training.\n",
            "Found 592 files belonging to 2 classes.\n",
            "Using 88 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.layers import Activation  # Add this import for Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Create a Sequential model\n",
        "model_1 = Sequential()\n",
        "\n",
        "# Convolutional Layer 1\n",
        "model_1.add(Conv2D(64, (3, 3), activation=None, input_shape=(150, 150, 3)))\n",
        "model_1.add(BatchNormalization(axis=-1))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 2\n",
        "model_1.add(Conv2D(64, (3, 3), activation=None))\n",
        "model_1.add(BatchNormalization(axis=-1))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 3\n",
        "model_1.add(Conv2D(128, (3, 3), activation=None))\n",
        "model_1.add(BatchNormalization(axis=-1))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 4\n",
        "model_1.add(Conv2D(128, (3, 3), activation=None))\n",
        "model_1.add(BatchNormalization(axis=-1))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 5\n",
        "model_1.add(Conv2D(256, (3, 3), activation=None))\n",
        "model_1.add(BatchNormalization(axis=-1))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 6\n",
        "model_1.add(Conv2D(256, (3, 3), padding='same', activation=None))\n",
        "model_1.add(BatchNormalization(axis=-1))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# Flatten the feature maps\n",
        "model_1.add(Flatten())\n",
        "\n",
        "# Fully Connected Layer 1\n",
        "model_1.add(Dense(512, activation='relu'))\n",
        "model_1.add(BatchNormalization(axis=-1))\n",
        "# Fully Connected Layer 2\n",
        "model_1.add(Dense(256, activation='relu'))\n",
        "model_1.add(BatchNormalization(axis=-1))\n",
        "# Fully Connected Layer 3\n",
        "model_1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0006)\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model_1.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZDtFS3F8Ril",
        "outputId": "3e0e41ae-6c79-4a1d-8ccd-9b35121b5247"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 64)      1792      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 148, 148, 64)      256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 148, 148, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 74, 74, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 72, 72, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 72, 72, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 34, 34, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 34, 34, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 15, 15, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 15, 15, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 5, 5, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 5, 5, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 5, 5, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 2, 2, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 2, 2, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 1, 1, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 512)               2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1415233 (5.40 MB)\n",
            "Trainable params: 1411905 (5.39 MB)\n",
            "Non-trainable params: 3328 (13.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.layers import Activation  # Add this import for Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Create a Sequential model\n",
        "model_2 = Sequential()\n",
        "\n",
        "# Convolutional Layer 1\n",
        "model_2.add(Conv2D(64, (3, 3), activation=None, input_shape=(150, 150, 3)))\n",
        "model_2.add(BatchNormalization(axis=-1))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 2\n",
        "model_2.add(Conv2D(64, (3, 3), activation=None))\n",
        "model_2.add(BatchNormalization(axis=-1))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 3\n",
        "model_2.add(Conv2D(128, (3, 3), activation=None))\n",
        "model_2.add(BatchNormalization(axis=-1))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 4\n",
        "model_2.add(Conv2D(128, (3, 3), activation=None))\n",
        "model_2.add(BatchNormalization(axis=-1))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 5\n",
        "model_2.add(Conv2D(256, (3, 3), activation=None))\n",
        "model_2.add(BatchNormalization(axis=-1))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 6\n",
        "model_2.add(Conv2D(256, (3, 3), padding='same', activation=None))\n",
        "model_2.add(BatchNormalization(axis=-1))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# Flatten the feature maps\n",
        "model_2.add(Flatten())\n",
        "\n",
        "# Fully Connected Layer 1\n",
        "model_2.add(Dense(512, activation='relu'))\n",
        "model_2.add(BatchNormalization(axis=-1))\n",
        "# Fully Connected Layer 2\n",
        "model_2.add(Dense(256, activation='relu'))\n",
        "model_2.add(BatchNormalization(axis=-1))\n",
        "# Fully Connected Layer 3\n",
        "model_2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0006)\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyCC14EHU_Yq",
        "outputId": "57c573de-8763-45d0-dec2-596dd2d041a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_26 (Conv2D)          (None, 148, 148, 64)      1792      \n",
            "                                                                 \n",
            " batch_normalization_28 (Ba  (None, 148, 148, 64)      256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 148, 148, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPooli  (None, 74, 74, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 74, 74, 64)        0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 72, 72, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_29 (Ba  (None, 72, 72, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 72, 72, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPooli  (None, 36, 36, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_30 (Ba  (None, 34, 34, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 34, 34, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPooli  (None, 17, 17, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_31 (Ba  (None, 15, 15, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 15, 15, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPooli  (None, 7, 7, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 5, 5, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_32 (Ba  (None, 5, 5, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 5, 5, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_34 (MaxPooli  (None, 2, 2, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_33 (Ba  (None, 2, 2, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_35 (MaxPooli  (None, 1, 1, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_34 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_35 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1415233 (5.40 MB)\n",
            "Trainable params: 1411905 (5.39 MB)\n",
            "Non-trainable params: 3328 (13.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.layers import Activation  # Add this import for Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Create a Sequential model\n",
        "model_3 = Sequential()\n",
        "\n",
        "# Convolutional Layer 1\n",
        "model_3.add(Conv2D(64, (3, 3), activation=None, input_shape=(150, 150, 3)))\n",
        "model_3.add(BatchNormalization(axis=-1))\n",
        "model_3.add(Activation('relu'))\n",
        "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_3.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 2\n",
        "model_3.add(Conv2D(64, (3, 3), activation=None))\n",
        "model_3.add(BatchNormalization(axis=-1))\n",
        "model_3.add(Activation('relu'))\n",
        "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_3.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 3\n",
        "model_3.add(Conv2D(128, (3, 3), activation=None))\n",
        "model_3.add(BatchNormalization(axis=-1))\n",
        "model_3.add(Activation('relu'))\n",
        "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_3.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 4\n",
        "model_3.add(Conv2D(128, (3, 3), activation=None))\n",
        "model_3.add(BatchNormalization(axis=-1))\n",
        "model_3.add(Activation('relu'))\n",
        "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_3.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 5\n",
        "model_3.add(Conv2D(256, (3, 3), activation=None))\n",
        "model_3.add(BatchNormalization(axis=-1))\n",
        "model_3.add(Activation('relu'))\n",
        "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_3.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional Layer 6\n",
        "model_3.add(Conv2D(256, (3, 3), padding='same', activation=None))\n",
        "model_3.add(BatchNormalization(axis=-1))\n",
        "model_3.add(Activation('relu'))\n",
        "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_3.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# Flatten the feature maps\n",
        "model_3.add(Flatten())\n",
        "\n",
        "# Fully Connected Layer 1\n",
        "model_3.add(Dense(512, activation='relu'))\n",
        "model_3.add(BatchNormalization(axis=-1))\n",
        "# Fully Connected Layer 2\n",
        "model_3.add(Dense(256, activation='relu'))\n",
        "model_3.add(BatchNormalization(axis=-1))\n",
        "# Fully Connected Layer 3\n",
        "model_3.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0006)\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model_3.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QaZtINHipAE",
        "outputId": "6bde715e-6012-44e5-a5b5-7c7dce1797fe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_32 (Conv2D)          (None, 148, 148, 64)      1792      \n",
            "                                                                 \n",
            " batch_normalization_36 (Ba  (None, 148, 148, 64)      256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 148, 148, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPooli  (None, 74, 74, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 74, 74, 64)        0         \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 72, 72, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_37 (Ba  (None, 72, 72, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 72, 72, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_37 (MaxPooli  (None, 36, 36, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_38 (Ba  (None, 34, 34, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 34, 34, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPooli  (None, 17, 17, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_39 (Ba  (None, 15, 15, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 15, 15, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPooli  (None, 7, 7, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 5, 5, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_40 (Ba  (None, 5, 5, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 5, 5, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPooli  (None, 2, 2, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_41 (Ba  (None, 2, 2, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_41 (MaxPooli  (None, 1, 1, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_42 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_43 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1415233 (5.40 MB)\n",
            "Trainable params: 1411905 (5.39 MB)\n",
            "Non-trainable params: 3328 (13.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(train_ds_1, epochs=50, batch_size=32, validation_data=val_ds_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuCEOIhI809h",
        "outputId": "e48fc480-e45a-4444-8b6e-a20430d1dba1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 23s 423ms/step - loss: 0.7180 - accuracy: 0.7143 - val_loss: 3.7716 - val_accuracy: 0.5682\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 5s 147ms/step - loss: 0.4742 - accuracy: 0.7976 - val_loss: 2.4486 - val_accuracy: 0.5682\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 3s 144ms/step - loss: 0.3203 - accuracy: 0.8849 - val_loss: 0.5754 - val_accuracy: 0.6364\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 4s 180ms/step - loss: 0.1548 - accuracy: 0.9484 - val_loss: 1.0855 - val_accuracy: 0.4318\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 5s 275ms/step - loss: 0.1973 - accuracy: 0.9365 - val_loss: 1.0217 - val_accuracy: 0.4318\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 4s 138ms/step - loss: 0.1313 - accuracy: 0.9524 - val_loss: 0.5665 - val_accuracy: 0.6136\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 3s 143ms/step - loss: 0.1297 - accuracy: 0.9524 - val_loss: 1.5623 - val_accuracy: 0.4318\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 4s 183ms/step - loss: 0.1359 - accuracy: 0.9603 - val_loss: 1.5940 - val_accuracy: 0.4318\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 4s 140ms/step - loss: 0.0514 - accuracy: 0.9802 - val_loss: 0.3583 - val_accuracy: 0.9091\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 3s 139ms/step - loss: 0.1130 - accuracy: 0.9643 - val_loss: 1.0791 - val_accuracy: 0.4773\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 4s 170ms/step - loss: 0.1169 - accuracy: 0.9524 - val_loss: 1.2648 - val_accuracy: 0.4545\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 4s 142ms/step - loss: 0.0646 - accuracy: 0.9762 - val_loss: 0.5124 - val_accuracy: 0.7273\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 3s 140ms/step - loss: 0.0858 - accuracy: 0.9643 - val_loss: 1.6374 - val_accuracy: 0.4545\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 3s 142ms/step - loss: 0.1102 - accuracy: 0.9524 - val_loss: 0.1908 - val_accuracy: 0.8636\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 5s 274ms/step - loss: 0.0608 - accuracy: 0.9722 - val_loss: 1.0223 - val_accuracy: 0.5682\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 3s 141ms/step - loss: 0.0980 - accuracy: 0.9563 - val_loss: 0.2296 - val_accuracy: 0.8864\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 5s 276ms/step - loss: 0.0855 - accuracy: 0.9762 - val_loss: 0.9137 - val_accuracy: 0.6136\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 4s 179ms/step - loss: 0.0293 - accuracy: 0.9881 - val_loss: 1.4972 - val_accuracy: 0.5909\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 3s 142ms/step - loss: 0.0551 - accuracy: 0.9762 - val_loss: 0.5959 - val_accuracy: 0.7955\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 3s 139ms/step - loss: 0.1252 - accuracy: 0.9524 - val_loss: 3.7513 - val_accuracy: 0.4318\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 6s 277ms/step - loss: 0.0392 - accuracy: 0.9881 - val_loss: 3.5271 - val_accuracy: 0.4318\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 3s 138ms/step - loss: 0.0769 - accuracy: 0.9683 - val_loss: 3.1948 - val_accuracy: 0.4318\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 3s 173ms/step - loss: 0.0279 - accuracy: 0.9881 - val_loss: 2.5242 - val_accuracy: 0.5455\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 4s 142ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 1.9449 - val_accuracy: 0.6364\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 3s 140ms/step - loss: 0.0394 - accuracy: 0.9881 - val_loss: 2.3289 - val_accuracy: 0.6364\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 3s 139ms/step - loss: 0.0288 - accuracy: 0.9881 - val_loss: 0.9480 - val_accuracy: 0.7955\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 5s 182ms/step - loss: 0.0296 - accuracy: 0.9881 - val_loss: 1.4804 - val_accuracy: 0.6591\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 3s 141ms/step - loss: 0.0281 - accuracy: 0.9841 - val_loss: 1.1457 - val_accuracy: 0.7273\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 3s 140ms/step - loss: 0.0186 - accuracy: 0.9921 - val_loss: 1.2157 - val_accuracy: 0.7727\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 4s 182ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.7512 - val_accuracy: 0.8182\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 4s 140ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 2.0690 - val_accuracy: 0.6136\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 3s 140ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 1.3889 - val_accuracy: 0.7500\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 3s 142ms/step - loss: 0.0267 - accuracy: 0.9881 - val_loss: 0.5304 - val_accuracy: 0.8636\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 4s 142ms/step - loss: 0.0339 - accuracy: 0.9881 - val_loss: 1.1012 - val_accuracy: 0.7955\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 3s 142ms/step - loss: 0.0236 - accuracy: 0.9960 - val_loss: 2.9960 - val_accuracy: 0.5455\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 4s 181ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 4.5088 - val_accuracy: 0.4545\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 4s 142ms/step - loss: 0.0361 - accuracy: 0.9802 - val_loss: 4.0422 - val_accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 3s 143ms/step - loss: 0.0270 - accuracy: 0.9881 - val_loss: 0.3208 - val_accuracy: 0.9318\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 3s 139ms/step - loss: 0.0275 - accuracy: 0.9881 - val_loss: 0.9313 - val_accuracy: 0.8182\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 5s 182ms/step - loss: 0.0393 - accuracy: 0.9841 - val_loss: 0.8553 - val_accuracy: 0.7955\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 3s 141ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.5969 - val_accuracy: 0.8636\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 3s 147ms/step - loss: 0.0857 - accuracy: 0.9683 - val_loss: 3.3114 - val_accuracy: 0.4773\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 3s 141ms/step - loss: 0.0390 - accuracy: 0.9841 - val_loss: 0.4819 - val_accuracy: 0.9091\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 5s 185ms/step - loss: 0.0315 - accuracy: 0.9841 - val_loss: 1.6274 - val_accuracy: 0.7045\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 4s 179ms/step - loss: 0.0180 - accuracy: 0.9921 - val_loss: 3.7354 - val_accuracy: 0.5227\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 3s 142ms/step - loss: 0.0444 - accuracy: 0.9841 - val_loss: 4.0277 - val_accuracy: 0.5227\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 4s 180ms/step - loss: 0.0799 - accuracy: 0.9722 - val_loss: 2.4901 - val_accuracy: 0.6136\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 5s 142ms/step - loss: 0.0160 - accuracy: 0.9881 - val_loss: 0.9026 - val_accuracy: 0.7955\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 3s 146ms/step - loss: 0.0209 - accuracy: 0.9960 - val_loss: 0.4130 - val_accuracy: 0.9091\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 3s 145ms/step - loss: 0.0384 - accuracy: 0.9802 - val_loss: 0.1996 - val_accuracy: 0.9091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_2 = model_2.fit(train_ds_2, epochs=50, batch_size=32, validation_data=val_ds_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIDF5u9k9BZH",
        "outputId": "57d894ff-b106-4e18-e4b8-94b47e4d9393"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 12s 291ms/step - loss: 0.5235 - accuracy: 0.7725 - val_loss: 0.7489 - val_accuracy: 0.4697\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 6s 294ms/step - loss: 0.2767 - accuracy: 0.8836 - val_loss: 1.4245 - val_accuracy: 0.4697\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 5s 221ms/step - loss: 0.1938 - accuracy: 0.9180 - val_loss: 4.4919 - val_accuracy: 0.4697\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 7s 326ms/step - loss: 0.2004 - accuracy: 0.9286 - val_loss: 0.8140 - val_accuracy: 0.5909\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 5s 217ms/step - loss: 0.1212 - accuracy: 0.9497 - val_loss: 3.4578 - val_accuracy: 0.4697\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 5s 222ms/step - loss: 0.1736 - accuracy: 0.9286 - val_loss: 1.9674 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 7s 282ms/step - loss: 0.1302 - accuracy: 0.9471 - val_loss: 0.4878 - val_accuracy: 0.7576\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 5s 224ms/step - loss: 0.1249 - accuracy: 0.9603 - val_loss: 1.0530 - val_accuracy: 0.6515\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 6s 282ms/step - loss: 0.1321 - accuracy: 0.9497 - val_loss: 0.4988 - val_accuracy: 0.7727\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 5s 219ms/step - loss: 0.0780 - accuracy: 0.9762 - val_loss: 0.5186 - val_accuracy: 0.8636\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 6s 347ms/step - loss: 0.1111 - accuracy: 0.9656 - val_loss: 0.3126 - val_accuracy: 0.8788\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 6s 219ms/step - loss: 0.0718 - accuracy: 0.9656 - val_loss: 0.2090 - val_accuracy: 0.8939\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 5s 220ms/step - loss: 0.0987 - accuracy: 0.9656 - val_loss: 0.1411 - val_accuracy: 0.9697\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 7s 283ms/step - loss: 0.1161 - accuracy: 0.9762 - val_loss: 0.9212 - val_accuracy: 0.7121\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 5s 216ms/step - loss: 0.0620 - accuracy: 0.9603 - val_loss: 0.7511 - val_accuracy: 0.7424\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 6s 283ms/step - loss: 0.0402 - accuracy: 0.9841 - val_loss: 0.5289 - val_accuracy: 0.7879\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 5s 216ms/step - loss: 0.0465 - accuracy: 0.9815 - val_loss: 1.6064 - val_accuracy: 0.6061\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 6s 327ms/step - loss: 0.0525 - accuracy: 0.9762 - val_loss: 0.4468 - val_accuracy: 0.8182\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 5s 218ms/step - loss: 0.0259 - accuracy: 0.9947 - val_loss: 0.1110 - val_accuracy: 0.9545\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 7s 346ms/step - loss: 0.0363 - accuracy: 0.9921 - val_loss: 1.7240 - val_accuracy: 0.6212\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 5s 219ms/step - loss: 0.1051 - accuracy: 0.9603 - val_loss: 0.4884 - val_accuracy: 0.8485\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 5s 218ms/step - loss: 0.0532 - accuracy: 0.9788 - val_loss: 0.1292 - val_accuracy: 0.9091\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 7s 250ms/step - loss: 0.0657 - accuracy: 0.9762 - val_loss: 2.0648 - val_accuracy: 0.5303\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 5s 219ms/step - loss: 0.0669 - accuracy: 0.9841 - val_loss: 2.2574 - val_accuracy: 0.5758\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 6s 292ms/step - loss: 0.0424 - accuracy: 0.9815 - val_loss: 0.0255 - val_accuracy: 0.9848\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 6s 215ms/step - loss: 0.0227 - accuracy: 0.9894 - val_loss: 3.7963 - val_accuracy: 0.4848\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 6s 333ms/step - loss: 0.0194 - accuracy: 0.9947 - val_loss: 0.3114 - val_accuracy: 0.8333\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 5s 218ms/step - loss: 0.0423 - accuracy: 0.9894 - val_loss: 0.0560 - val_accuracy: 0.9848\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 5s 218ms/step - loss: 0.0547 - accuracy: 0.9762 - val_loss: 1.8219 - val_accuracy: 0.6818\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 7s 290ms/step - loss: 0.0518 - accuracy: 0.9841 - val_loss: 3.6071 - val_accuracy: 0.5152\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 5s 219ms/step - loss: 0.0461 - accuracy: 0.9762 - val_loss: 3.1989 - val_accuracy: 0.5303\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 5s 265ms/step - loss: 0.0502 - accuracy: 0.9841 - val_loss: 5.7246 - val_accuracy: 0.4697\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 7s 220ms/step - loss: 0.0161 - accuracy: 0.9921 - val_loss: 5.9970 - val_accuracy: 0.4697\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 5s 219ms/step - loss: 0.0149 - accuracy: 0.9974 - val_loss: 3.4713 - val_accuracy: 0.5455\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 6s 339ms/step - loss: 0.0668 - accuracy: 0.9815 - val_loss: 4.2807 - val_accuracy: 0.4848\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 5s 220ms/step - loss: 0.0469 - accuracy: 0.9788 - val_loss: 0.5555 - val_accuracy: 0.8333\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 7s 345ms/step - loss: 0.0203 - accuracy: 0.9921 - val_loss: 3.4048 - val_accuracy: 0.5909\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 5s 216ms/step - loss: 0.0249 - accuracy: 0.9894 - val_loss: 0.0787 - val_accuracy: 0.9697\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 7s 344ms/step - loss: 0.0186 - accuracy: 0.9894 - val_loss: 0.0623 - val_accuracy: 0.9394\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 5s 221ms/step - loss: 0.0209 - accuracy: 0.9947 - val_loss: 0.4320 - val_accuracy: 0.8333\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 5s 230ms/step - loss: 0.0301 - accuracy: 0.9921 - val_loss: 0.1897 - val_accuracy: 0.9242\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 7s 258ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.8636\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 5s 219ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9848\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 8s 348ms/step - loss: 0.0407 - accuracy: 0.9841 - val_loss: 0.0674 - val_accuracy: 0.9697\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 5s 276ms/step - loss: 0.0147 - accuracy: 0.9921 - val_loss: 1.8738 - val_accuracy: 0.6364\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 6s 287ms/step - loss: 0.0272 - accuracy: 0.9894 - val_loss: 0.1628 - val_accuracy: 0.9545\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 5s 219ms/step - loss: 0.0305 - accuracy: 0.9868 - val_loss: 0.6721 - val_accuracy: 0.8485\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 7s 327ms/step - loss: 0.0197 - accuracy: 0.9894 - val_loss: 0.0853 - val_accuracy: 0.9545\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 5s 215ms/step - loss: 0.0429 - accuracy: 0.9894 - val_loss: 0.3659 - val_accuracy: 0.9242\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 7s 341ms/step - loss: 0.0210 - accuracy: 0.9894 - val_loss: 0.1672 - val_accuracy: 0.9394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_3 = model_3.fit(train_ds_3, epochs=50, batch_size=32, validation_data=val_ds_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7nG2Fb4jCg9",
        "outputId": "cbc38885-4dea-43b5-f87f-ff299c9f1e8f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 13s 416ms/step - loss: 0.5818 - accuracy: 0.7440 - val_loss: 3.9818 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 8s 311ms/step - loss: 0.3176 - accuracy: 0.8810 - val_loss: 4.8389 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 7s 267ms/step - loss: 0.2474 - accuracy: 0.9107 - val_loss: 1.5088 - val_accuracy: 0.4659\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 8s 253ms/step - loss: 0.1841 - accuracy: 0.9226 - val_loss: 2.2826 - val_accuracy: 0.4659\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 6s 245ms/step - loss: 0.1679 - accuracy: 0.9444 - val_loss: 3.1694 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 8s 270ms/step - loss: 0.1528 - accuracy: 0.9425 - val_loss: 0.4024 - val_accuracy: 0.8409\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 6s 246ms/step - loss: 0.1513 - accuracy: 0.9504 - val_loss: 1.1289 - val_accuracy: 0.5795\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 8s 300ms/step - loss: 0.1535 - accuracy: 0.9365 - val_loss: 0.2734 - val_accuracy: 0.8864\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 6s 248ms/step - loss: 0.0907 - accuracy: 0.9663 - val_loss: 0.3971 - val_accuracy: 0.8068\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 9s 361ms/step - loss: 0.1386 - accuracy: 0.9385 - val_loss: 1.4026 - val_accuracy: 0.5682\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 6s 247ms/step - loss: 0.1038 - accuracy: 0.9603 - val_loss: 0.1710 - val_accuracy: 0.9205\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 8s 334ms/step - loss: 0.1099 - accuracy: 0.9583 - val_loss: 3.3990 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 6s 248ms/step - loss: 0.0799 - accuracy: 0.9683 - val_loss: 0.9641 - val_accuracy: 0.6932\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 8s 351ms/step - loss: 0.0986 - accuracy: 0.9663 - val_loss: 1.6388 - val_accuracy: 0.6136\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 7s 273ms/step - loss: 0.0643 - accuracy: 0.9742 - val_loss: 0.2864 - val_accuracy: 0.9091\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 8s 361ms/step - loss: 0.0455 - accuracy: 0.9802 - val_loss: 0.0562 - val_accuracy: 0.9659\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 6s 246ms/step - loss: 0.0760 - accuracy: 0.9702 - val_loss: 0.8665 - val_accuracy: 0.7727\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 7s 276ms/step - loss: 0.0481 - accuracy: 0.9821 - val_loss: 0.0475 - val_accuracy: 0.9773\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 8s 345ms/step - loss: 0.0744 - accuracy: 0.9762 - val_loss: 0.3144 - val_accuracy: 0.9091\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 6s 247ms/step - loss: 0.0686 - accuracy: 0.9722 - val_loss: 0.2109 - val_accuracy: 0.9205\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 7s 298ms/step - loss: 0.0413 - accuracy: 0.9861 - val_loss: 0.1996 - val_accuracy: 0.9318\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 6s 264ms/step - loss: 0.0317 - accuracy: 0.9921 - val_loss: 1.4518 - val_accuracy: 0.6250\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 8s 336ms/step - loss: 0.0211 - accuracy: 0.9901 - val_loss: 0.0405 - val_accuracy: 0.9773\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 7s 272ms/step - loss: 0.0536 - accuracy: 0.9821 - val_loss: 0.2025 - val_accuracy: 0.9432\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 6s 243ms/step - loss: 0.0421 - accuracy: 0.9821 - val_loss: 0.2170 - val_accuracy: 0.9432\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 8s 360ms/step - loss: 0.0263 - accuracy: 0.9901 - val_loss: 0.2720 - val_accuracy: 0.9091\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 6s 242ms/step - loss: 0.0288 - accuracy: 0.9861 - val_loss: 0.0500 - val_accuracy: 0.9773\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 8s 397ms/step - loss: 0.0453 - accuracy: 0.9821 - val_loss: 0.8084 - val_accuracy: 0.8295\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 6s 242ms/step - loss: 0.0292 - accuracy: 0.9901 - val_loss: 0.6712 - val_accuracy: 0.8295\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 6s 244ms/step - loss: 0.0448 - accuracy: 0.9861 - val_loss: 0.0612 - val_accuracy: 0.9773\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 7s 305ms/step - loss: 0.0243 - accuracy: 0.9881 - val_loss: 0.5594 - val_accuracy: 0.8182\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 6s 245ms/step - loss: 0.0149 - accuracy: 0.9940 - val_loss: 1.7340 - val_accuracy: 0.6250\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 8s 342ms/step - loss: 0.0385 - accuracy: 0.9861 - val_loss: 0.1082 - val_accuracy: 0.9659\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 6s 245ms/step - loss: 0.0228 - accuracy: 0.9901 - val_loss: 0.0685 - val_accuracy: 0.9773\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 8s 364ms/step - loss: 0.0206 - accuracy: 0.9901 - val_loss: 0.1441 - val_accuracy: 0.9432\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 6s 239ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.1995 - val_accuracy: 0.9318\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 8s 394ms/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 0.0569 - val_accuracy: 0.9773\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 6s 245ms/step - loss: 0.0108 - accuracy: 0.9980 - val_loss: 0.1094 - val_accuracy: 0.9545\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 8s 336ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 2.6564 - val_accuracy: 0.5341\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 7s 270ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 8s 340ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 3.4986 - val_accuracy: 0.5114\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 6s 241ms/step - loss: 0.0481 - accuracy: 0.9841 - val_loss: 0.0517 - val_accuracy: 0.9659\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 8s 358ms/step - loss: 0.0288 - accuracy: 0.9901 - val_loss: 2.0714 - val_accuracy: 0.6250\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 6s 243ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 1.8254 - val_accuracy: 0.7045\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 8s 390ms/step - loss: 0.0183 - accuracy: 0.9960 - val_loss: 5.6118 - val_accuracy: 0.5114\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 6s 247ms/step - loss: 0.0084 - accuracy: 0.9960 - val_loss: 3.4166 - val_accuracy: 0.5341\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 6s 244ms/step - loss: 0.0097 - accuracy: 0.9960 - val_loss: 2.6980 - val_accuracy: 0.6023\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 10s 365ms/step - loss: 0.0366 - accuracy: 0.9861 - val_loss: 1.0902 - val_accuracy: 0.7386\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 6s 245ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.1918 - val_accuracy: 0.9432\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 8s 275ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.2326 - val_accuracy: 0.9318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "test_ds = tensorflow.keras.utils.image_dataset_from_directory(\n",
        "    directory='/content/Dataset/xray_dataset_covid19/test',\n",
        "    image_size=(150, 150),\n",
        "    shuffle=False  # No need to shuffle the test dataset\n",
        ")\n",
        "\n",
        "# Make predictions\n",
        "y_pred=model_1.predict(test_ds)\n",
        "y_pred = [np.rint(i)[0] for i in y_pred]\n",
        "y_true = []\n",
        "for images, labels in test_ds:\n",
        "    y_true.extend(labels.numpy())\n",
        "\n",
        "y_pred=model_1.predict(test_ds)\n",
        "y_pred = [np.rint(i)[0] for i in y_pred]\n",
        "y_true = []\n",
        "# Iterate through the dataset to collect unique labels\n",
        "for images, labels in test_ds:\n",
        "    y_true.extend(labels.numpy())\n",
        "# Calculate metrics\n",
        "print(classification_report(y_true, y_pred, target_names=test_ds.class_names))\n",
        "\n",
        "\n",
        "\n",
        "# Calculate and print sensitivity and specificity for each class\n",
        "for i, class_name in enumerate(test_ds.class_names):\n",
        "    sensitivity = cm[i, i] / cm[i, :].sum()\n",
        "    true_negatives = np.delete(np.delete(cm, i, axis=0), i, axis=1).sum()\n",
        "    false_positives = cm[:, i].sum() - cm[i, i]\n",
        "    specificity = true_negatives / (true_negatives + false_positives)\n",
        "    print(f\"{class_name} - Sensitivity (Recall): {sensitivity:.4f}, Specificity: {specificity:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnbADvfTSGVi",
        "outputId": "dad0d707-829f-44c8-a3cb-5302ad4a7c3c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40 files belonging to 2 classes.\n",
            "2/2 [==============================] - 1s 98ms/step\n",
            "2/2 [==============================] - 0s 66ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       COVID       0.95      1.00      0.98        20\n",
            "      NORMAL       1.00      0.95      0.97        20\n",
            "\n",
            "    accuracy                           0.97        40\n",
            "   macro avg       0.98      0.97      0.97        40\n",
            "weighted avg       0.98      0.97      0.97        40\n",
            "\n",
            "COVID - Sensitivity (Recall): 0.9500, Specificity: 1.0000\n",
            "NORMAL - Sensitivity (Recall): 1.0000, Specificity: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "test_ds = tensorflow.keras.utils.image_dataset_from_directory(\n",
        "    directory='/content/Dataset/xray_dataset_covid19/test',\n",
        "    image_size=(150, 150),\n",
        "    shuffle=False  # No need to shuffle the test dataset\n",
        ")\n",
        "\n",
        "# Make predictions\n",
        "y_pred=model_2.predict(test_ds)\n",
        "y_pred = [np.rint(i)[0] for i in y_pred]\n",
        "y_true = []\n",
        "for images, labels in test_ds:\n",
        "    y_true.extend(labels.numpy())\n",
        "\n",
        "y_pred=model_2.predict(test_ds)\n",
        "y_pred = [np.rint(i)[0] for i in y_pred]\n",
        "y_true = []\n",
        "# Iterate through the dataset to collect unique labels\n",
        "for images, labels in test_ds:\n",
        "    y_true.extend(labels.numpy())\n",
        "# Calculate metrics\n",
        "print(classification_report(y_true, y_pred, target_names=test_ds.class_names))\n",
        "\n",
        "\n",
        "\n",
        "# Calculate and print sensitivity and specificity for each class\n",
        "for i, class_name in enumerate(test_ds.class_names):\n",
        "    sensitivity = cm[i, i] / cm[i, :].sum()\n",
        "    true_negatives = np.delete(np.delete(cm, i, axis=0), i, axis=1).sum()\n",
        "    false_positives = cm[:, i].sum() - cm[i, i]\n",
        "    specificity = true_negatives / (true_negatives + false_positives)\n",
        "    print(f\"{class_name} - Sensitivity (Recall): {sensitivity:.4f}, Specificity: {specificity:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTFIySFiV6Gc",
        "outputId": "5e879875-c223-4c35-c9b8-c40d6f99198b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40 files belonging to 2 classes.\n",
            "2/2 [==============================] - 0s 52ms/step\n",
            "2/2 [==============================] - 0s 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       COVID       1.00      0.95      0.97        20\n",
            "      NORMAL       0.95      1.00      0.98        20\n",
            "\n",
            "    accuracy                           0.97        40\n",
            "   macro avg       0.98      0.97      0.97        40\n",
            "weighted avg       0.98      0.97      0.97        40\n",
            "\n",
            "COVID - Sensitivity (Recall): 0.9500, Specificity: 1.0000\n",
            "NORMAL - Sensitivity (Recall): 1.0000, Specificity: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "test_ds = tensorflow.keras.utils.image_dataset_from_directory(\n",
        "    directory='/content/Dataset/xray_dataset_covid19/test',\n",
        "    image_size=(150, 150),\n",
        "    shuffle=False  # No need to shuffle the test dataset\n",
        ")\n",
        "\n",
        "# Make predictions\n",
        "y_pred=model_3.predict(test_ds)\n",
        "y_pred = [np.rint(i)[0] for i in y_pred]\n",
        "y_true = []\n",
        "for images, labels in test_ds:\n",
        "    y_true.extend(labels.numpy())\n",
        "\n",
        "y_pred=model_3.predict(test_ds)\n",
        "y_pred = [np.rint(i)[0] for i in y_pred]\n",
        "y_true = []\n",
        "# Iterate through the dataset to collect unique labels\n",
        "for images, labels in test_ds:\n",
        "    y_true.extend(labels.numpy())\n",
        "# Calculate metrics\n",
        "print(classification_report(y_true, y_pred, target_names=test_ds.class_names))\n",
        "\n",
        "\n",
        "# Calculate and print sensitivity and specificity for each class\n",
        "for i, class_name in enumerate(test_ds.class_names):\n",
        "    sensitivity = cm[i, i] / cm[i, :].sum()\n",
        "    true_negatives = np.delete(np.delete(cm, i, axis=0), i, axis=1).sum()\n",
        "    false_positives = cm[:, i].sum() - cm[i, i]\n",
        "    specificity = true_negatives / (true_negatives + false_positives)\n",
        "    print(f\"{class_name} - Sensitivity (Recall): {sensitivity:.4f}, Specificity: {specificity:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uj_pseifDeg",
        "outputId": "2351df2e-5351-4aa6-b7a0-8038d645a90f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40 files belonging to 2 classes.\n",
            "2/2 [==============================] - 1s 92ms/step\n",
            "2/2 [==============================] - 1s 107ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       COVID       1.00      0.95      0.97        20\n",
            "      NORMAL       0.95      1.00      0.98        20\n",
            "\n",
            "    accuracy                           0.97        40\n",
            "   macro avg       0.98      0.97      0.97        40\n",
            "weighted avg       0.98      0.97      0.97        40\n",
            "\n",
            "COVID - Sensitivity (Recall): 0.9500, Specificity: 1.0000\n",
            "NORMAL - Sensitivity (Recall): 1.0000, Specificity: 0.9500\n"
          ]
        }
      ]
    }
  ]
}